{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/gerritgr/nextaid_bdprocess/blob/main/Full_Autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKd5y0k64DJC"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm as notebook_tqdm\n",
    "#from .autonotebook import tqdm as notebook_tqdm\n",
    "import random\n",
    "import networkx as nx\n",
    "import os\n",
    "import pickle \n",
    "import time\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "HOME ='./'\n",
    "THIS_FILE = 'Full_Autoencoder.ipynb'   # very ugly to get automatically, needed to autosave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LATENT_DIM = 128\n",
    "NUM_ATOMTYPES = 43 #https://www.blopig.com/blog/2022/02/how-to-turn-a-smiles-string-into-a-molecular-graph-for-pytorch-geometric/\n",
    "LEARNING_RATE = 0.000001\n",
    "BATCH_SIZE = 32#\n",
    "ACCEPT_PEAK_THRESHOLD = 0.3\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig( format = '%(asctime)s  %(levelname)-10s %(processName)s  %(name)s %(message)s', level = logging.INFO, filename = THIS_FILE+\"_my.log\")\n",
    "\n",
    "    \n",
    "def printlog(*args, **kw):\n",
    "    output = ', '.join([str(a) for a in args])\n",
    "    kwargs = [str((k,v)) for k,v in kw.items()]\n",
    "    output = output + ' - '+ ', '.join(kwargs)\n",
    "    logging.info(output) \n",
    "    try:\n",
    "        print(*args, **kw)\n",
    "    except:\n",
    "        print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('HIVspectra_graph_data_full.pickle'):\n",
    "    import shutil\n",
    "    printlog('unpack HIVspectra_graph_data_full')\n",
    "    shutil.unpack_archive('HIVspectra_graph_data_full.zip', './')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack overflow\n",
    "def str_to_float(s, encoding=\"utf-8\"):\n",
    "  from zlib import crc32\n",
    "  def bytes_to_float(b):\n",
    "    return float(crc32(b) & 0xffffffff) / 2**32\n",
    "  return bytes_to_float(s.encode(encoding))\n",
    "\n",
    "\n",
    "# very important to make results reproducible\n",
    "def set_seed(exp_name):\n",
    "    name_as_int = int(str_to_float(exp_name)*10000000)\n",
    "    np.random.seed(name_as_int)\n",
    "    torch.random.manual_seed(name_as_int)\n",
    "    random.seed(name_as_int) \n",
    "    \n",
    "set_seed('1234')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_experiment(exp_name):\n",
    "    set_seed(exp_name)\n",
    "    exp_name = HOME + exp_name\n",
    "    os.system('mkdir ' + exp_name)\n",
    "    os.system('mkdir '+ exp_name + '/weights')\n",
    "    os.system('cp \"'+THIS_FILE+'\" '+exp_name+'/main_notebook.ipynb')\n",
    "    return exp_name\n",
    "\n",
    "\n",
    "def load_model(exp_folder_path):\n",
    "  filepath = sorted(list(glob.glob(exp_folder_path + '/weights/training_state*')))\n",
    "  if len(filepath) == 0:\n",
    "    return None\n",
    "  state = torch.load(filepath[-1], map_location=DEVICE)\n",
    "  printlog('Found state file: ', filepath)\n",
    "  return state\n",
    "\n",
    "def plot_inputoutput(input_output, path):\n",
    "    x_values = input_output[0]\n",
    "    y_values = input_output[1]\n",
    "    try:\n",
    "        x_values = x_values[:3000]\n",
    "        y_values = y_values[:3000]\n",
    "    except:\n",
    "        pass\n",
    "    plt.clf()\n",
    "    plt.scatter(x_values, y_values, edgecolors='blue', color='None', alpha=0.3)\n",
    "    plt.xlabel('Real Peak Num')\n",
    "    plt.ylabel('Predicted Peak Num')\n",
    "    plt.title('Training Data')\n",
    "    plt.savefig(path)\n",
    "    \n",
    "\n",
    "def reduce_vector(y, length_new=128):\n",
    "    assert(length_new <= y.numel())\n",
    "    \n",
    "    y_flat = y.flatten()\n",
    "    y_new = y_flat[:length_new] * 0.0 # to get same type/device\n",
    "    length_old = y_flat.numel()\n",
    "    for i in range(length_old):\n",
    "        i_new = (float(i)/length_old)*length_new\n",
    "        i_new = int(i_new)\n",
    "        y_new[i_new] += y_flat[i]\n",
    "        \n",
    "    return y_new\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss and Acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Multi-Scale Encoder Loss and Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(length_of_list):\n",
    "    sublist_num = 0.5\n",
    "    index_list = list()\n",
    "    while True:\n",
    "        sublist_num = int(sublist_num*2)\n",
    "        sublist_len = int(length_of_list/sublist_num)\n",
    "        assert(int(sublist_len * sublist_num) == int(length_of_list))\n",
    "        for i in range(sublist_num):\n",
    "            index_list.append((i*sublist_len, (i+1)*sublist_len)) \n",
    "        if int(sublist_num) == int(length_of_list):\n",
    "            break\n",
    "    return index_list\n",
    "\n",
    "# accepts only flattened tensors\n",
    "def fill_to_pow2(x):\n",
    "    l = x.shape[1]\n",
    "    p = int(math.log2(l))\n",
    "    l_new = int(l - 2**p)\n",
    "    if l_new == 0:\n",
    "        return x\n",
    "    l_diff = int(2**(p+1) - l)\n",
    "    mean_vec =  torch.mean(x, dim=1, keepdim =True)\n",
    "    x = torch.cat((x, mean_vec.repeat(1, l_diff)), dim=1) \n",
    "    return x\n",
    "\n",
    "# operates in-place (flatten)\n",
    "# only works on vectors of length 2^x or will extend tensors accordingly\n",
    "def compute_diff(l1, l2, advanced_weight=True):\n",
    "    assert l1.shape == l2.shape\n",
    "    assert len(l1.shape) in [1, 2]\n",
    "    # first dim is batch\n",
    "    if len(l1.shape) == 1:\n",
    "        l1 = l1.reshape(1,-1)\n",
    "        l2 = l2.reshape(1,-1)\n",
    "    \n",
    "\n",
    "    l1 = fill_to_pow2(l1)\n",
    "    l2 = fill_to_pow2(l2)\n",
    "\n",
    "    indices = split_list(l1.shape[1])\n",
    "    diff = torch.sum(l1, dim=1, keepdim=True)*0.0  # to have tensor on correct decice and tpye\n",
    "    for (i1, i2) in indices:\n",
    "        sum1 = torch.sum(l1[:, i1:i2], dim=1, keepdim=True)\n",
    "        sum2 = torch.sum(l2[:, i1:i2], dim=1, keepdim=True)\n",
    "        diff_i = (sum1-sum2)**2\n",
    "        if advanced_weight:\n",
    "            diff_i = diff_i * (i2-i1)/len(l1)\n",
    "        diff = diff + diff_i \n",
    "    return diff\n",
    "\n",
    "\n",
    "def compute_acc(out, gt, peak_threshold = ACCEPT_PEAK_THRESHOLD):\n",
    "    try:\n",
    "        out = out.flatten().detach().cpu().tolist()\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        gt = gt.flatten().detach().cpu().tolist()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    pred = [1.0 if out[i] > peak_threshold else 0.0 for i in range(len(out))]\n",
    "    gt = [1.0 if gt[i]>0.5 else 0.0 for i in range(len(gt))]\n",
    "    \n",
    "    gt_pred_intersec =  [1.0 if gt[i]>0.5 and pred[i] >0.5 else 0.0 for i in range(len(gt))]\n",
    "    gt_pred_union =  [1.0 if gt[i]>0.5 or pred[i] >0.5 else 0.0 for i in range(len(gt))]\n",
    "    \n",
    "    # compute jaccard\n",
    "    return np.sum(gt_pred_intersec)/np.sum(gt_pred_union)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN-Based Graph Distance Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import ModuleList, Linear, ReLU, Sequential\n",
    "from torch_geometric.nn import PNAConv, BatchNorm, global_add_pool\n",
    "\n",
    "class GNN_ENC(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels=LATENT_DIM, node_input_size=79, edge_input_size=10, out_channel=128, depth_graph=10, depth_mlp=5):\n",
    "        super(GNN_ENC, self).__init__()\n",
    "        \n",
    "        # Graph layers\n",
    "        self.convs = ModuleList()\n",
    "        self.convs.append(PDNConv(node_input_size, hidden_channels, edge_dim=edge_input_size, hidden_channels=hidden_channels))\n",
    "        for _ in range(depth_graph-1): \n",
    "            self.convs.append(PDNConv(hidden_channels, hidden_channels, edge_dim=edge_input_size, hidden_channels=hidden_channels))\n",
    "        \n",
    "        # Final MLP        \n",
    "        mlp_list = list()\n",
    "        for _ in range(depth_mlp-1):\n",
    "            mlp_list.append(Linear(hidden_channels, hidden_channels))\n",
    "            mlp_list.append(ReLU())\n",
    "        mlp_list.append(Linear(hidden_channels, out_channel))\n",
    "        self.mlp = Sequential(*mlp_list)\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr,  batch):\n",
    "\n",
    "        # Graph layers\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = F.relu(conv(x, edge_index, edge_attr))\n",
    "        x = F.relu(conv(x, edge_index, edge_attr))\n",
    "        \n",
    "        # Readout layer\n",
    "        x = global_add_pool(x, batch)  \n",
    "\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.1, training=self.training)\n",
    "        x = self.mlp(x)\n",
    "        x = x**2\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNUSED\n",
    "class GNN_DEC(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels=LATENT_DIM, max_number_of_nodes=10, depth_mlp=15):\n",
    "        super(GNN_DEC, self).__init__()\n",
    "        \n",
    "        self.out_channel = int(max_number_of_nodes*(max_number_of_nodes-1)/2+max_number_of_nodes)  # size of upper triangular matrix with diagonal\n",
    "        \n",
    "        # MLP        \n",
    "        mlp_list = list()\n",
    "        for _ in range(depth_mlp-1):\n",
    "            mlp_list.append(Linear(hidden_channels, hidden_channels))\n",
    "            mlp_list.append(ReLU())\n",
    "        mlp_list.append(Linear(hidden_channels, self.out_channel))\n",
    "        self.mlp = Sequential(*mlp_list)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.mlp(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder Atom Count Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN_DEC_Atomcount(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels=LATENT_DIM, number_atomtypes=NUM_ATOMTYPES, depth_mlp=15):\n",
    "        super(GNN_DEC_Atomcount, self).__init__()\n",
    "        \n",
    "        self.out_channel = number_atomtypes\n",
    "        \n",
    "        # MLP        \n",
    "        mlp_list = list()\n",
    "        for _ in range(depth_mlp-1):\n",
    "            mlp_list.append(Linear(hidden_channels, hidden_channels))\n",
    "            mlp_list.append(ReLU())\n",
    "        mlp_list.append(Linear(hidden_channels, self.out_channel))\n",
    "        self.mlp = Sequential(*mlp_list)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        atom_count_vec = self.mlp(x)\n",
    "        \n",
    "        return atom_count_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        self.encoder = GNN_ENC().to(DEVICE)\n",
    "        self.decoder = GNN_DEC_Atomcount().to(DEVICE)\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        pred_spectrum = self.encoder(x, edge_index, edge_attr, batch)\n",
    "        pred_atom_count_vec = self.decoder(pred_spectrum)\n",
    "\n",
    "        return pred_spectrum, pred_atom_count_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure batch size is 1\n",
    "@torch.no_grad()\n",
    "def visualize(data_loader, model, path):\n",
    "    model.eval()\n",
    "\n",
    "    for i, data in enumerate(data_loader):\n",
    "      data = data.to(DEVICE)\n",
    "      out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "      out = out.flatten().detach().cpu().tolist()\n",
    "      y = data.y.flatten().detach().cpu().tolist()\n",
    "\n",
    "      plt.close()\n",
    "      plt.plot(out, alpha=0.6)\n",
    "      plt.plot(y, alpha=0.5)\n",
    "      plt.savefig(path.replace('NUM', str(i).zfill(4)),  bbox_inches='tight', dpi=300)\n",
    "        \n",
    "      plt.clf()\n",
    "    \n",
    "    \n",
    "      pred = [(i, 1.0) if out[i] > ACCEPT_PEAK_THRESHOLD else (i,0.0) for i in range(len(out))]\n",
    "      gt = [(i, 1.0) if y[i]>0.5 else (i, 0.0) for i in range(len(y))]\n",
    "    \n",
    "      #gt = [(i, y[i]) for i in range(len(y)) if y[i] > 0.9]\n",
    "      #pred = [(i, -out[i]) for i in range(len(out)) if out[i] > 0.40 and out[i] >= out[max(0,i-1)] and out[i] >= out[min(len(out)-1, i+1)]]\n",
    "      #plt.scatter([x[0] for x in gt], [x[1] for x in gt], alpha=0.8)\n",
    "      #plt.scatter([x[0] for x in pred], [x[1] for x in pred], alpha=0.8)\n",
    "    \n",
    "      plt.scatter([0, len(out)], [0, 1.0], alpha=0.0, c='black')  #dummy\n",
    "      for x,y in gt:\n",
    "          plt.axvline(x=x, c='red', alpha=0.5, ls='--', lw=3, label='gt')\n",
    "      for x,y in pred:\n",
    "          plt.axvline(x=x, c='blue', alpha=0.5, label='pred')\n",
    "            \n",
    "      plt.legend()      \n",
    "      plt.savefig(path.replace('NUM', 'scatter_'+str(i).zfill(4)),  bbox_inches='tight', dpi=300)\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    spectrum_loss_list = list()\n",
    "    count_loss_list = list()\n",
    "    l1_loss = nn.L1Loss()\n",
    "\n",
    "    for data in train_loader:  \n",
    "        data = data.to(DEVICE)\n",
    "        optimizer.zero_grad()  \n",
    "        pred_spectrum, pred_atom_count_vec = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "        gt_spectrum = data.y.reshape(pred_spectrum.shape)\n",
    "\n",
    "        # latent loss to optimize spectra\n",
    "        spectrum_loss = compute_diff(gt_spectrum, pred_spectrum)\n",
    "        spectrum_loss = torch.mean(spectrum_loss) # reduce to dim 1\n",
    "\n",
    "        # count loss to optimize reconstruction\n",
    "        gt_atom_count_vec = global_add_pool(data.x[:,:NUM_ATOMTYPES], data.batch)\n",
    "        count_loss = l1_loss(gt_atom_count_vec, pred_atom_count_vec)\n",
    "\n",
    "        loss = spectrum_loss + count_loss\n",
    "\n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "\n",
    "        spectrum_loss_list.append(spectrum_loss.item())\n",
    "        count_loss_list.append(count_loss.item())\n",
    "    return np.mean(spectrum_loss_list), np.mean(count_loss_list) # only correct when each batch equally sized\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data_loader):\n",
    "    model.eval()\n",
    "    spectrum_acc_list = list()\n",
    "    count_loss_list = list()\n",
    "    l1_loss = nn.L1Loss()\n",
    "\n",
    "    for data in data_loader:\n",
    "        data = data.to(DEVICE)\n",
    "        pred_spectrum, pred_atom_count_vec = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "        \n",
    "        # spectrum loss\n",
    "        y = data.y.reshape(pred_spectrum.shape)\n",
    "        for j in range(pred_spectrum.shape[0]):\n",
    "            out_line = pred_spectrum[j,:]\n",
    "            gt_line = y[j,:]\n",
    "            acc = compute_acc(out_line, gt_line)\n",
    "            spectrum_acc_list.append(acc)\n",
    "\n",
    "        # count loss to optimize reconstruction\n",
    "        gt_atom_count_vec = global_add_pool(data.x[:,:NUM_ATOMTYPES], data.batch)\n",
    "        count_loss = l1_loss(gt_atom_count_vec, pred_atom_count_vec)\n",
    "        count_loss_list.append(count_loss.item())\n",
    "        \n",
    "    return  np.mean(spectrum_acc_list), np.mean(count_loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(exp_name, model, train_loader, test_loader, optimizer, viz_loader = None, epoch_num = 1000):\n",
    "    set_seed(exp_name)\n",
    "    printlog('Start experiment: ', exp_name)\n",
    "    epoch_num += 1 # because we start with epoch 1\n",
    "    exp_folder_path = setup_experiment(exp_name)\n",
    "    epoch_start = 1\n",
    "\n",
    "    # load model\n",
    "    state = load_model(exp_folder_path)\n",
    "    if state is not None:\n",
    "        optimizer.load_state_dict(state['optimizer'])\n",
    "        model.load_state_dict(state['state_dict'])\n",
    "        epoch_start = state['epoch']\n",
    "        \n",
    "    for epoch in range(epoch_start, epoch_num):\n",
    "        start = time.time()\n",
    "        spectrum_loss_train, count_loss_train = train(model, train_loader, optimizer)\n",
    "        end = time.time()\n",
    "        epoch_time = end - start\n",
    "        if epoch == epoch_start or epoch % 100 == 0 or epoch == epoch_num-1 or epoch<10:\n",
    "            spectrum_acc_train, count_loss_train = test(model, train_loader)\n",
    "            spectrum_acc_test, count_loss_test = test(model, test_loader)\n",
    "            s = repr(f'Epoch: {epoch:03d}, Spectrum Loss: {spectrum_loss_train:.4f}, Count Loss: {count_loss_train:.4f}, Train Jaccard: {spectrum_acc_train:.4f}, Test Jaccard: {spectrum_acc_test:.4f}, Epoch Time: {epoch_time:.5f}')\n",
    "            printlog(s)\n",
    "\n",
    "            state = {'optimizer': optimizer.state_dict(), 'epoch': epoch+1, 'state_dict': model.state_dict()} \n",
    "            torch.save(state, exp_folder_path+'/weights/training_state.pickle')\n",
    "            if viz_loader is not None:\n",
    "                visualize(viz_loader, model, exp_folder_path+'/prediction_{}_NUM.png'.format(str(epoch).zfill(10)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read reduced graph file\n"
     ]
    }
   ],
   "source": [
    "graph_data = None\n",
    "try:\n",
    "    graph_data = pickle.load(open('HIVspectra_graph_data_reduced_{}.pickle'.format(int(LATENT_DIM)), \"rb\"))\n",
    "    print('read reduced graph file')\n",
    "except:\n",
    "    print('create reduced file')\n",
    "    graph_data = pickle.load(open('HIVspectra_graph_data_full.pickle', \"rb\"))\n",
    "    for graph in graph_data:\n",
    "        graph.y = reduce_vector(graph.y, length_new = LATENT_DIM)\n",
    "    pickle.dump(graph_data, open('HIVspectra_graph_data_reduced_{}.pickle'.format(int(LATENT_DIM)), \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = int(len(graph_data)*0.8)\n",
    "graph_data_train = graph_data[0:c]\n",
    "graph_data_test = graph_data[c:]\n",
    "\n",
    "train_loader = DataLoader(graph_data_train, batch_size=BATCH_SIZE, shuffle=True)  \n",
    "test_loader = DataLoader(graph_data_test, batch_size=BATCH_SIZE)\n",
    "viz_loader = DataLoader(graph_data_train[:20], batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start experiment:  exp1_autoenc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./exp1_autoenc’: File exists\n",
      "mkdir: cannot create directory ‘./exp1_autoenc/weights’: File exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Epoch: 001, Spectrum Loss: 1706.4960, Count Loss: 0.6233, Train Jaccard: 0.0000, Test Jaccard: 0.0000, Epoch Time: 165.37094'\n"
     ]
    }
   ],
   "source": [
    "GNN_autoenc = Autoencoder()\n",
    "GNN_autoenc = GNN_autoenc.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(GNN_autoenc.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "run_experiment('exp1_autoenc', GNN_autoenc, train_loader, test_loader, optimizer, viz_loader = None, epoch_num = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP17PI3t4CIjnQvwZUZPhYI",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
